{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOzxRQur5sAffB+T5uh2gjI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WJvHGBqmAQD1","outputId":"5192022d-e005-4a04-b877-83c6c0548734","executionInfo":{"status":"ok","timestamp":1731593759322,"user_tz":-480,"elapsed":184577,"user":{"displayName":"Tong Wu","userId":"04187078703020700412"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Removing columns with high missing values:\n","original_reg_date    0.989943\n","fuel_type            0.764886\n","opc_scheme           0.994029\n","lifespan             0.905629\n","indicative_price     1.000000\n","dtype: float64\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 35000 entries, 1292132 to 1311711\n","Data columns (total 19 columns):\n"," #   Column           Non-Null Count  Dtype  \n","---  ------           --------------  -----  \n"," 0   make             33143 non-null  object \n"," 1   model            35000 non-null  object \n"," 2   manufactured     34990 non-null  float64\n"," 3   reg_date         35000 non-null  object \n"," 4   type_of_vehicle  35000 non-null  object \n"," 5   category         35000 non-null  object \n"," 6   transmission     35000 non-null  object \n"," 7   curb_weight      34583 non-null  float64\n"," 8   power            31274 non-null  float64\n"," 9   engine_cap       34169 non-null  float64\n"," 10  no_of_owners     34974 non-null  float64\n"," 11  depreciation     34292 non-null  float64\n"," 12  coe              35000 non-null  int64  \n"," 13  road_tax         31286 non-null  float64\n"," 14  dereg_value      34697 non-null  float64\n"," 15  mileage          27530 non-null  float64\n"," 16  omv              34907 non-null  float64\n"," 17  arf              34761 non-null  float64\n"," 18  eco_category     35000 non-null  object \n","dtypes: float64(11), int64(1), object(7)\n","memory usage: 5.3+ MB\n","Removing columns with high duplicate values:\n","eco_category    1\n","dtype: int64\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 35000 entries, 1292132 to 1311711\n","Data columns (total 18 columns):\n"," #   Column           Non-Null Count  Dtype  \n","---  ------           --------------  -----  \n"," 0   make             33143 non-null  object \n"," 1   model            35000 non-null  object \n"," 2   manufactured     34990 non-null  float64\n"," 3   reg_date         35000 non-null  object \n"," 4   type_of_vehicle  35000 non-null  object \n"," 5   category         35000 non-null  object \n"," 6   transmission     35000 non-null  object \n"," 7   curb_weight      34583 non-null  float64\n"," 8   power            31274 non-null  float64\n"," 9   engine_cap       34169 non-null  float64\n"," 10  no_of_owners     34974 non-null  float64\n"," 11  depreciation     34292 non-null  float64\n"," 12  coe              35000 non-null  int64  \n"," 13  road_tax         31286 non-null  float64\n"," 14  dereg_value      34697 non-null  float64\n"," 15  mileage          27530 non-null  float64\n"," 16  omv              34907 non-null  float64\n"," 17  arf              34761 non-null  float64\n","dtypes: float64(11), int64(1), object(6)\n","memory usage: 5.1+ MB\n","civic: ['unknown' 'honda']\n","golf: ['unknown' 'volkswagen']\n","cooper: ['unknown' 'mini']\n","hiace: ['unknown' 'toyota']\n","fit: ['honda' 'unknown']\n","vezel: ['honda' 'unknown']\n","altis: ['toyota' 'unknown']\n","forester: ['subaru' 'unknown']\n","harrier: ['toyota' 'unknown']\n","elantra: ['hyundai' 'unknown']\n","amg: ['mercedes-benz' 'unknown']\n","qashqai: ['nissan' 'unknown']\n","shuttle: ['honda' 'unknown']\n","wish: ['toyota' 'unknown']\n","cerato: ['kia' 'unknown']\n","jazz: ['honda' 'unknown']\n","corolla: ['toyota' 'unknown']\n","dyna: ['toyota' 'unknown']\n","alphard: ['toyota' 'unknown']\n","avante: ['hyundai' 'unknown']\n","civic: ['unknown' 'honda']\n","golf: ['unknown' 'volkswagen']\n","cooper: ['unknown' 'mini']\n","hiace: ['unknown' 'toyota']\n","fit: ['honda' 'unknown']\n","vezel: ['honda' 'unknown']\n","altis: ['toyota' 'unknown']\n","forester: ['subaru' 'unknown']\n","harrier: ['toyota' 'unknown']\n","elantra: ['hyundai' 'unknown']\n","amg: ['mercedes-benz' 'unknown']\n","qashqai: ['nissan' 'unknown']\n","shuttle: ['honda' 'unknown']\n","wish: ['toyota' 'unknown']\n","cerato: ['kia' 'unknown']\n","jazz: ['honda' 'unknown']\n","corolla: ['toyota' 'unknown']\n","dyna: ['toyota' 'unknown']\n","alphard: ['toyota' 'unknown']\n","avante: ['hyundai' 'unknown']\n","Filled missing values in make column\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 35000 entries, 1292132 to 1311711\n","Data columns (total 17 columns):\n"," #   Column           Non-Null Count  Dtype  \n","---  ------           --------------  -----  \n"," 0   make             35000 non-null  object \n"," 1   model            35000 non-null  object \n"," 2   type_of_vehicle  35000 non-null  object \n"," 3   category         35000 non-null  object \n"," 4   transmission     35000 non-null  object \n"," 5   curb_weight      34583 non-null  float64\n"," 6   power            31274 non-null  float64\n"," 7   engine_cap       34169 non-null  float64\n"," 8   no_of_owners     34974 non-null  float64\n"," 9   depreciation     34292 non-null  float64\n"," 10  coe              35000 non-null  int64  \n"," 11  road_tax         31286 non-null  float64\n"," 12  dereg_value      34697 non-null  float64\n"," 13  mileage          27530 non-null  float64\n"," 14  omv              34907 non-null  float64\n"," 15  arf              34761 non-null  float64\n"," 16  reg_year         35000 non-null  int32  \n","dtypes: float64(10), int32(1), int64(1), object(5)\n","memory usage: 4.7+ MB\n","type_of_vehicle col is extracted to 11 cols\n","category col is extracted to 16 cols\n","transmission col is extracted to 2 cols\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 35000 entries, 1292132 to 1311711\n","Data columns (total 41 columns):\n"," #   Column                   Non-Null Count  Dtype  \n","---  ------                   --------------  -----  \n"," 0   curb_weight              34583 non-null  float64\n"," 1   power                    31274 non-null  float64\n"," 2   engine_cap               34169 non-null  float64\n"," 3   no_of_owners             34974 non-null  float64\n"," 4   depreciation             34292 non-null  float64\n"," 5   coe                      35000 non-null  int64  \n"," 6   road_tax                 31286 non-null  float64\n"," 7   dereg_value              34697 non-null  float64\n"," 8   mileage                  27530 non-null  float64\n"," 9   omv                      34907 non-null  float64\n"," 10  arf                      34761 non-null  float64\n"," 11  reg_year                 35000 non-null  int32  \n"," 12  bus/mini bus             35000 non-null  int64  \n"," 13  hatchback                35000 non-null  int64  \n"," 14  luxury sedan             35000 non-null  int64  \n"," 15  mid-sized sedan          35000 non-null  int64  \n"," 16  mpv                      35000 non-null  int64  \n"," 17  others                   35000 non-null  int64  \n"," 18  sports car               35000 non-null  int64  \n"," 19  stationwagon             35000 non-null  int64  \n"," 20  suv                      35000 non-null  int64  \n"," 21  truck                    35000 non-null  int64  \n"," 22  van                      35000 non-null  int64  \n"," 23  -                        35000 non-null  int64  \n"," 24  almost new car           35000 non-null  int64  \n"," 25  coe car                  35000 non-null  int64  \n"," 26  consignment car          35000 non-null  int64  \n"," 27  direct owner sale        35000 non-null  int64  \n"," 28  electric cars            35000 non-null  int64  \n"," 29  hybrid cars              35000 non-null  int64  \n"," 30  imported used vehicle    35000 non-null  int64  \n"," 31  low mileage car          35000 non-null  int64  \n"," 32  opc car                  35000 non-null  int64  \n"," 33  parf car                 35000 non-null  int64  \n"," 34  premium ad car           35000 non-null  int64  \n"," 35  rare & exotic            35000 non-null  int64  \n"," 36  sgcarmart warranty cars  35000 non-null  int64  \n"," 37  sta evaluated car        35000 non-null  int64  \n"," 38  vintage cars             35000 non-null  int64  \n"," 39  auto                     35000 non-null  int64  \n"," 40  manual                   35000 non-null  int64  \n","dtypes: float64(10), int32(1), int64(30)\n","memory usage: 11.1 MB\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 34997 entries, 1292132 to 1311711\n","Data columns (total 41 columns):\n"," #   Column                   Non-Null Count  Dtype  \n","---  ------                   --------------  -----  \n"," 0   curb_weight              34580 non-null  float64\n"," 1   power                    31271 non-null  float64\n"," 2   engine_cap               34166 non-null  float64\n"," 3   no_of_owners             34971 non-null  float64\n"," 4   depreciation             34289 non-null  float64\n"," 5   coe                      34997 non-null  int64  \n"," 6   road_tax                 31283 non-null  float64\n"," 7   dereg_value              34694 non-null  float64\n"," 8   mileage                  27527 non-null  float64\n"," 9   omv                      34904 non-null  float64\n"," 10  arf                      34758 non-null  float64\n"," 11  reg_year                 34997 non-null  int32  \n"," 12  bus/mini bus             34997 non-null  int64  \n"," 13  hatchback                34997 non-null  int64  \n"," 14  luxury sedan             34997 non-null  int64  \n"," 15  mid-sized sedan          34997 non-null  int64  \n"," 16  mpv                      34997 non-null  int64  \n"," 17  others                   34997 non-null  int64  \n"," 18  sports car               34997 non-null  int64  \n"," 19  stationwagon             34997 non-null  int64  \n"," 20  suv                      34997 non-null  int64  \n"," 21  truck                    34997 non-null  int64  \n"," 22  van                      34997 non-null  int64  \n"," 23  -                        34997 non-null  int64  \n"," 24  almost new car           34997 non-null  int64  \n"," 25  coe car                  34997 non-null  int64  \n"," 26  consignment car          34997 non-null  int64  \n"," 27  direct owner sale        34997 non-null  int64  \n"," 28  electric cars            34997 non-null  int64  \n"," 29  hybrid cars              34997 non-null  int64  \n"," 30  imported used vehicle    34997 non-null  int64  \n"," 31  low mileage car          34997 non-null  int64  \n"," 32  opc car                  34997 non-null  int64  \n"," 33  parf car                 34997 non-null  int64  \n"," 34  premium ad car           34997 non-null  int64  \n"," 35  rare & exotic            34997 non-null  int64  \n"," 36  sgcarmart warranty cars  34997 non-null  int64  \n"," 37  sta evaluated car        34997 non-null  int64  \n"," 38  vintage cars             34997 non-null  int64  \n"," 39  auto                     34997 non-null  int64  \n"," 40  manual                   34997 non-null  int64  \n","dtypes: float64(10), int32(1), int64(30)\n","memory usage: 11.1 MB\n","LR RMSE: 42670.94781894124\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   23.8s\n","[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   59.3s\n","[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.4min finished\n","[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n","[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n","[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.3s\n","[Parallel(n_jobs=2)]: Done 300 out of 300 | elapsed:    0.4s finished\n"]},{"output_type":"stream","name":"stdout","text":["RF RMSE: 27362.415061901487\n","LASSO RMSE: 42670.83452727414\n"]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"modeling.ipynb\n","\n","Automatically generated by Colab.\n","\n","Original file is located at\n","    https://colab.research.google.com/drive/1FywCo2ods8bIB6ot9bUIGxGdqekxz7p6\n","\"\"\"\n","#%%\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.ensemble import RandomForestRegressor\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from tqdm import tqdm\n","\n","pd.set_option(\"display.max_columns\",None)\n","pd.set_option(\"display.max_rows\",None)\n","pd.set_option(\"display.max_colwidth\",None)\n","\n","#%%\n","\n","# Load data\n","train_data = pd.read_csv(\"train.csv\", index_col=\"listing_id\")\n","test_data = pd.read_csv(\"test.csv\", index_col=\"listing_id\")\n","train_index = train_data.index\n","test_index = test_data.index\n","\n","merge_data = pd.concat([train_data, test_data], axis=0).drop(columns=[\"price\"])\n","\n","merge_data = merge_data.drop(\n","    columns=[\"title\", \"description\", \"features\", \"accessories\"]\n",")\n","\n","# %%\n","\n","# Remove those almost na cols.\n","def remove_high_na_columns(data: pd.DataFrame, threshold=0.3):\n","    na_rate = data.isna().mean()\n","    high_na_columns = na_rate[na_rate > threshold]\n","    print(f\"Removing columns with high missing values:\\n{high_na_columns}\")\n","    data = data.drop(columns=high_na_columns.index)\n","    return data\n","\n","\n","merge_data = remove_high_na_columns(merge_data)\n","merge_data.info()\n","\n","# %%\n","\n","# Remove those cols with all the same values.\n","def remove_one_value_columns(data: pd.DataFrame):\n","    duplicate_rate = data.apply(lambda col: col.nunique())\n","    high_duplicate_columns = duplicate_rate[duplicate_rate == 1]\n","    print(f\"Removing columns with high duplicate values:\\n{high_duplicate_columns}\")\n","    data = data.drop(columns=high_duplicate_columns.index)\n","    return data\n","\n","\n","merge_data = remove_one_value_columns(merge_data)\n","merge_data.info()\n","\n","# %%\n","\n","# Inspect on reg_date and manufactured, we can see they are highly related. So remove manufactured(has na values).\n","merge_data[\"reg_date\"] = pd.to_datetime(merge_data[\"reg_date\"], format=r\"%d-%b-%Y\")\n","merge_data[\"reg_year\"] = merge_data[\"reg_date\"].dt.year\n","merge_data[[\"reg_year\", \"manufactured\"]].corr()\n","\n","\n","# %%\n","\n","merge_data = merge_data.drop(columns=[\"reg_date\", \"manufactured\"])\n","\n","# %%\n","\n","# Inspect on make and model, we can find that for those rows which only has model value, we can inference the make.\n","def inspect_make_model(data: pd.DataFrame):\n","    data[\"make\"] = data[\"make\"].fillna(\"unknown\")\n","    model_with_unknown_make = data.loc[data[\"make\"] == \"unknown\", \"model\"].unique()\n","    for model in model_with_unknown_make:\n","        print(f\"{model}: {data.loc[data['model'] == model, 'make'].unique()}\")\n","\n","\n","inspect_make_model(merge_data)\n","\n","# %%\n","\n","# Inspect on make and model, we can find that for those rows which only has model value, we can inference the make.\n","def inspect_make_model(data: pd.DataFrame):\n","    data[\"make\"] = data[\"make\"].fillna(\"unknown\")\n","    model_with_unknown_make = data.loc[data[\"make\"] == \"unknown\", \"model\"].unique()\n","    for model in model_with_unknown_make:\n","        print(f\"{model}: {data.loc[data['model'] == model, 'make'].unique()}\")\n","\n","\n","inspect_make_model(merge_data)\n","\n","# %%\n","\n","# fill missing make value\n","\n","\n","def process_make(data: pd.DataFrame):\n","    data[\"make\"] = data[\"make\"].fillna(\"unknown\")\n","\n","    model_with_unknown_make = data.loc[data[\"make\"] == \"unknown\", \"model\"].unique()\n","    model_make_map = (\n","        data[\n","            (data[\"model\"].isin(model_with_unknown_make)) & (data[\"make\"] != \"unknown\")\n","        ]\n","        .drop_duplicates(\"model\")\n","        .set_index(\"model\")[\"make\"]\n","        .to_dict()\n","    )\n","    loc_to_fill = data[\"make\"] == \"unknown\"\n","    data.loc[loc_to_fill, \"make\"] = data.loc[loc_to_fill, \"model\"].map(model_make_map)\n","\n","    print(\"Filled missing values in make column\")\n","\n","    return data\n","\n","\n","merge_data = process_make(merge_data)\n","merge_data.info()\n","\n","# %%\n","\n","# Notice that type_of_vehicle, category, transmission three variables are like tags, extract and convert them to dummies.\n","\n","\n","def process_type_of_vehicle(data: pd.DataFrame):\n","    type_of_vehicle = data[\"type_of_vehicle\"].str.get_dummies()\n","    data = pd.concat([data, type_of_vehicle], axis=1)\n","    data = data.drop(columns=[\"type_of_vehicle\"])\n","    print(f\"type_of_vehicle col is extracted to {len(type_of_vehicle.columns)} cols\")\n","    return data\n","\n","\n","def process_category(data: pd.DataFrame):\n","    category = data[\"category\"].str.get_dummies(sep=\", \")\n","    data = pd.concat([data, category], axis=1)\n","    data = data.drop(columns=[\"category\"])\n","\n","    print(f\"category col is extracted to {len(category.columns)} cols\")\n","\n","    return data\n","\n","\n","def process_transmission(data: pd.DataFrame):\n","    transmission = data[\"transmission\"].str.get_dummies()\n","    data = pd.concat([data, transmission], axis=1)\n","    data = data.drop(columns=[\"transmission\"])\n","    print(f\"transmission col is extracted to {len(transmission.columns)} cols\")\n","    return data\n","\n","\n","def process_make_model(data: pd.DataFrame):\n","    make = data[\"make\"].str.get_dummies()\n","    data = pd.concat([data, make], axis=1)\n","    data = data.drop(columns=[\"make\", \"model\"])\n","    print(f\"make col is extracted to {len(make.columns)} cols\")\n","    return data\n","\n","\n","merge_data = process_type_of_vehicle(merge_data)\n","merge_data = process_category(merge_data)\n","merge_data = process_transmission(merge_data)\n","\n","# make 转或者不转 dummy,影响后边的内容\n","merge_data = merge_data.drop(columns=['make', 'model'])\n","# merge_data = process_make_model(merge_data)\n","merge_data.info()\n","\n","# %%\n","\n","# 年平均行驶里程超过 10w 英里，真有点逆天了吧\n","high_mileage_indices = merge_data[\n","    ((merge_data[\"mileage\"] / (2025 - merge_data[\"reg_year\"])) > 1e5)\n","].index\n","train_data.loc[high_mileage_indices][\n","    [\"make\", \"model\", \"manufactured\", \"mileage\", \"price\"]\n","]\n","merge_data = merge_data.drop(high_mileage_indices)\n","\n","# %%\n","\n","merge_data.info()\n","\n","# %%\n","\n","# Begin to fill numeric na values\n","numeric_feats = merge_data.select_dtypes(include=[np.number]).columns\n","dummy_feats = merge_data.select_dtypes(include=[bool]).columns\n","\n","\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.impute import KNNImputer\n","\n","# 定义插补方法\n","iterative_imputer = IterativeImputer(\n","    max_iter=20, random_state=0, keep_empty_features=True, verbose=1\n",")\n","\n","\n","def custom_impute_by_make(data):\n","    # Step 1: 按 (make, model) 组内插补\n","    for (make, model), group in data.groupby([\"make\", \"model\"]):\n","        if len(group) >= 10:  # 检查组大小\n","            imputed_values = iterative_imputer.fit_transform(group[numeric_feats])\n","            data.loc[group.index, numeric_feats] = imputed_values\n","\n","    # Step 2: 对于尚未填补的缺失值，按 make 组插补\n","    for make, group in data.groupby(\"make\"):\n","        if len(group) >= 10:  # 检查组大小\n","            missing_indices = group[group.isnull().any(axis=1)].index\n","            if not missing_indices.empty:\n","                data.loc[group.index, numeric_feats] = iterative_imputer.fit_transform(\n","                    group[numeric_feats]\n","                )\n","\n","    # Step 3: 使用 全局 插补剩余缺失值\n","    remaining_na_indices = data[data.isnull().any(axis=1)].index\n","    if not remaining_na_indices.empty:\n","        data.loc[remaining_na_indices, numeric_feats] = iterative_imputer.fit_transform(\n","            group[numeric_feats]\n","        )\n","\n","    return data\n","\n","\n","\n","# 层次化插值还是直接插值补充\n","data_imputed = pd.DataFrame(\n","    iterative_imputer.fit_transform(merge_data),\n","    columns=merge_data.columns,\n","    index=merge_data.index,\n",")\n","\n","# %%\n","data_imputed.head()\n","\n","valid_train_index = train_index.intersection(data_imputed.index)\n","X = data_imputed.loc[valid_train_index]\n","y = train_data.loc[valid_train_index]['price']\n","\n","# X.corrwith(y).sort_values(ascending=False)\n","selected_feats = X.corrwith(y) > 0.05\n","selected_feats = selected_feats[selected_feats].index\n","\n","X = X[selected_feats]\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.ensemble import RandomForestRegressor\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from tqdm import tqdm\n","\n","def rf(X, y):\n","\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.2, random_state=42\n","    )\n","\n","    y_pred = []\n","    too_less = []\n","    for i in tqdm(range(len(X_test))):\n","\n","        rf_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n","\n","        row = X_test.iloc[i]\n","\n","        interest_index = (X_train[\"make\"] == row[\"make\"]) & (\n","            X_train[\"model\"] == row[\"model\"]\n","        )\n","\n","        # Step 1: 按 (make, model) 拟合\n","        if interest_index.sum() > 10:\n","            rf_model.fit(X_train[interest_index].drop(columns=['make', 'model']), y_train[interest_index])\n","\n","        else:\n","            interest_index = X_train[\"make\"] == row[\"make\"]\n","            # Step 2: 按 make 拟合\n","            if interest_index.sum() > 10:\n","                rf_model.fit(X_train[interest_index].drop(columns=['make', 'model']), y_train[interest_index])\n","\n","            # Step 3: 使用 全局 拟合\n","            else:\n","                too_less.append(1)\n","                rf_model.fit(X_train.drop(columns=['make', 'model']), y_train)\n","\n","        # 预测和计算 RMSE\n","        y_pred.append(rf_model.predict(pd.DataFrame([row.drop(['make', 'model'])]))[0])\n","    print(sum(too_less))\n","    mse = mean_squared_error(y_test, y_pred)\n","    print(f\"RF RMSE: {mse**0.5}\")\n","\n","    return rf_model\n","\n","\n","# rf_model1 = rf(X, y)\n","\n","# %%\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from tqdm import tqdm\n","\n","valid_train_index = train_index.intersection(data_imputed.index)\n","X = data_imputed.loc[valid_train_index]\n","y = train_data.loc[valid_train_index]['price']\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.2, random_state=42\n","    )\n","lr_model = LinearRegression()\n","lr_model.fit(X_train, y_train)\n","y_pred = lr_model.predict(X_test)\n","print(f\"LR RMSE: {mean_squared_error(y_test, y_pred)**0.5}\")\n","\n","# %%\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","rf_model = RandomForestRegressor(n_estimators=300, n_jobs=-1, verbose=1)\n","rf_model.fit(X_train, y_train)\n","y_pred = rf_model.predict(X_test)\n","print(f\"RF RMSE: {mean_squared_error(y_test, y_pred)**0.5}\")\n","\n","# %%\n","\n","from sklearn.linear_model import Lasso\n","from sklearn.preprocessing import MinMaxScaler\n","# 归一化数据\n","scaler = MinMaxScaler()\n","\n","X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n","X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n","\n","lasso_model = Lasso(alpha=0.01,max_iter=100000)\n","lasso_model.fit(X_train_scaled, y_train)\n","y_pred = lasso_model.predict(X_test_scaled)\n","\n","print(f\"LASSO RMSE: {mean_squared_error(y_test, y_pred)**0.5}\")\n","selected_data = X_train[X_train.columns[lasso_model.coef_ != 0]]\n","\n","\n","\n","# %%\n","\n","# y_pred = rf_model.predict(merge_data.loc[test_index].drop(columns=[\"make\", \"model\"]))\n","\n","\n","def save_submission(y_pred, filename=\"submission.csv\"):\n","    output = pd.DataFrame({\"Id\": range(len(y_pred)), \"Predicted\": y_pred})\n","    output.to_csv(filename, index=False)\n","\n","\n","# save_submission(y_pred, \"submission_rf_trained_all.csv\")"]}]}